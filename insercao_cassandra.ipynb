{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"insercao_cassandra.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1albILJ9-heJPa9EQuHE2AKwON5wl8QOu","authorship_tag":"ABX9TyNx8cb0eaB5WLsBZScZjMsV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Inserção no Banco de Dados Cassandra"],"metadata":{"id":"hyXwcPPjy3iF"}},{"cell_type":"markdown","source":["Importações necessárias para realizar esse código:"],"metadata":{"id":"wVbJYduyylKq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDnqik11uWjF"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *"]},{"cell_type":"markdown","source":["Inicialização da sessão do Spark e conexão com o Cassandra via a API **JDBC**:"],"metadata":{"id":"gpVTsVgFzFyi"}},{"cell_type":"code","source":["spark = SparkSession\\\n","    .builder\\\n","    .appName(\"Spark Exploration App\")\\\n","    .config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.1.0\")\\\n","    .config(\"spark.sql.extensions\",\"com.datastax.spark.connector.CassandraSparkExtensions\") \\\n","    .config(\"spark.cassandra.connection.host\",\"34.151.229.216\") \\\n","    .config(\"spark.cassandra.connection.port\",\"9042\") \\\n","    .getOrCreate()\n","    "],"metadata":{"id":"YkIS4BTMwF94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["keyspace = \"desafio_final\""],"metadata":{"id":"nH5HPobOwJ1C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Método criado para carregar os dados presentes em uma determinada tabela de um Keyspace:"],"metadata":{"id":"voSQMs2c0baT"}},{"cell_type":"code","source":["def loadData(table):\n","    df = spark.read \\\n","        .format(\"org.apache.spark.sql.cassandra\") \\\n","        .option(\"keyspace\", keyspace) \\\n","        .option(\"table\", table) \\\n","        .load()\n","    return df"],"metadata":{"id":"QdRnFoFiwMUr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Método criado para inserir os dados de um DataFrame em uma determinada tabela e Keyspace:"],"metadata":{"id":"jBws4G2A0sCa"}},{"cell_type":"code","source":["def saveData(df, table):\n","    df.write \\\n","        .format(\"org.apache.spark.sql.cassandra\") \\\n","        .option(\"keyspace\", keyspace) \\\n","        .option(\"table\", table) \\\n","        .mode('append') \\\n","        .save()"],"metadata":{"id":"MqFoHnnGwOYN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nessa parte do código estamos lendo os parquet cridos na etapa anterior e inseridos no Cloud Storage e transformandos os em DataFrames."],"metadata":{"id":"bhK1Y68R1hGj"}},{"cell_type":"code","source":["pib_agricola = spark.read.parquet('parquets/parquet_pib_agricola')\n","usa_usda = spark.read.parquet('parquets/parquet_usa_agricultura')\n","valor_producao = spark.read.parquet('parquets/parquet_valor_producao')\n","qnt_colheita = spark.read.parquet('parquets/quantidade_colheita')\n","exportacao_total = spark.read.parquet('parquets/total_exportacao')\n","exportacao_pais = spark.read.parquet('parquets/exportacao_pais')\n","exportacao_estado = spark.read.parquet('parquets/exportacao_estado')\n","exportacao_produto = spark.read.parquet('parquets/exportacao_produto')"],"metadata":{"id":"5LnljzPIwRJz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aqui estamos verificando se os DataFrames gerados com as leituras dos parquet estão corretos."],"metadata":{"id":"Tk1_4zH-30Z8"}},{"cell_type":"code","source":["pib_agricola.printSchema()\n","usa_usda.printSchema()\n","valor_producao.printSchema()\n","qnt_colheita.printSchema()\n","qnt_colheita.count()\n","exportacao_total.printSchema()\n","exportacao_pais.printSchema()\n","exportacao_estado.printSchema() \n","exportacao_produto.printSchema()"],"metadata":{"id":"KKxvN8MlwVXL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nessa parte estamos utilizando o método saveData para inserir o conteúdo de cada DataFrame nas respectivas tabelas do BD Cassandra."],"metadata":{"id":"ckH-EI2X2t8K"}},{"cell_type":"code","source":["saveData(pib_agricola,'pib_agricola')\n","saveData(usa_usda,'usa_agricultura')\n","saveData(valor_producao,'valor_producao')\n","saveData(qnt_colheita,'quantidade_colheita')\n","saveData(exportacao_total,'total_exportacao')\n","saveData(exportacao_pais,'exportacao_pais')\n","saveData(exportacao_estado,'exportacao_estado')\n","saveData(exportacao_produto,'exportacao_produto')"],"metadata":{"id":"J7nigFfRwpKa"},"execution_count":null,"outputs":[]}]}